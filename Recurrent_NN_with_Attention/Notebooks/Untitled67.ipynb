{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn23qmXnr5D_",
        "outputId": "2583307f-3809-4a07-dd2a-52a65ae77d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-21 15:16:35--  https://huggingface.co/garyw/clinical-embeddings-100d-w2v-cr/resolve/main/w2v_OA_CR_100d.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.4, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/e8/72/e872abef7b2278b5cf6a4f41d1455f5d309cdbd6310b2da0a6e9aecc840217e7/7f920b29a2c3861a475f296d397ff679528b064dbb51debf33568ae5f4f7e088?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27w2v_OA_CR_100d.bin%3B+filename%3D%22w2v_OA_CR_100d.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1719242195&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTI0MjE5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lOC83Mi9lODcyYWJlZjdiMjI3OGI1Y2Y2YTRmNDFkMTQ1NWY1ZDMwOWNkYmQ2MzEwYjJkYTBhNmU5YWVjYzg0MDIxN2U3LzdmOTIwYjI5YTJjMzg2MWE0NzVmMjk2ZDM5N2ZmNjc5NTI4YjA2NGRiYjUxZGViZjMzNTY4YWU1ZjRmN2UwODg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=lg6SjC3IQdBdgFNAziLEWVeYWF3AdhDsoMMO1jc12SBO2VSdUVXROF9MoAQKTnwVGlm8NwNX2Z5QPcgsiKVKuWFFFzxRJW3Bs9EAJfsRkYuNxZDTW8wpg1Xqsx7GFatUc%7EDsv14cjTz1DyB75rzJ-34YXY3n90%7EOAzSHXX4SptWvt80ZnHu0przR1%7Ev1dusmGW13jf4laEFo-bA%7EkF7sJgSO7yfM7PXikBNDcaNghkhC6%7ER-7cNLvYa73IIwY9WkZ0cM00YbPfFBn7YAz%7ETlu8zXLSmUHHoaQRBKQ8mEGdUjAGoA-d9yhhkMAX4aCJzc7ne%7E3550kkgw18vTlSu8mA__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-06-21 15:16:35--  https://cdn-lfs.huggingface.co/repos/e8/72/e872abef7b2278b5cf6a4f41d1455f5d309cdbd6310b2da0a6e9aecc840217e7/7f920b29a2c3861a475f296d397ff679528b064dbb51debf33568ae5f4f7e088?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27w2v_OA_CR_100d.bin%3B+filename%3D%22w2v_OA_CR_100d.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1719242195&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTI0MjE5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lOC83Mi9lODcyYWJlZjdiMjI3OGI1Y2Y2YTRmNDFkMTQ1NWY1ZDMwOWNkYmQ2MzEwYjJkYTBhNmU5YWVjYzg0MDIxN2U3LzdmOTIwYjI5YTJjMzg2MWE0NzVmMjk2ZDM5N2ZmNjc5NTI4YjA2NGRiYjUxZGViZjMzNTY4YWU1ZjRmN2UwODg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=lg6SjC3IQdBdgFNAziLEWVeYWF3AdhDsoMMO1jc12SBO2VSdUVXROF9MoAQKTnwVGlm8NwNX2Z5QPcgsiKVKuWFFFzxRJW3Bs9EAJfsRkYuNxZDTW8wpg1Xqsx7GFatUc%7EDsv14cjTz1DyB75rzJ-34YXY3n90%7EOAzSHXX4SptWvt80ZnHu0przR1%7Ev1dusmGW13jf4laEFo-bA%7EkF7sJgSO7yfM7PXikBNDcaNghkhC6%7ER-7cNLvYa73IIwY9WkZ0cM00YbPfFBn7YAz%7ETlu8zXLSmUHHoaQRBKQ8mEGdUjAGoA-d9yhhkMAX4aCJzc7ne%7E3550kkgw18vTlSu8mA__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.159.227.123, 108.159.227.71, 108.159.227.86, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.159.227.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24237857 (23M) [application/octet-stream]\n",
            "Saving to: ‘w2v_OA_CR_100d.bin’\n",
            "\n",
            "w2v_OA_CR_100d.bin  100%[===================>]  23.11M   100MB/s    in 0.2s    \n",
            "\n",
            "2024-06-21 15:16:36 (100 MB/s) - ‘w2v_OA_CR_100d.bin’ saved [24237857/24237857]\n",
            "\n",
            "--2024-06-21 15:16:36--  https://huggingface.co/garyw/clinical-embeddings-100d-w2v-cr/resolve/main/w2v_OA_CR_100d.bin.wv.vectors.npy\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.4, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/e8/72/e872abef7b2278b5cf6a4f41d1455f5d309cdbd6310b2da0a6e9aecc840217e7/72926d774155dfaef4763802927a53fa6315afc5ada32b5c797c4c8db9066bf4?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27w2v_OA_CR_100d.bin.wv.vectors.npy%3B+filename%3D%22w2v_OA_CR_100d.bin.wv.vectors.npy%22%3B&Expires=1719242196&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTI0MjE5Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lOC83Mi9lODcyYWJlZjdiMjI3OGI1Y2Y2YTRmNDFkMTQ1NWY1ZDMwOWNkYmQ2MzEwYjJkYTBhNmU5YWVjYzg0MDIxN2U3LzcyOTI2ZDc3NDE1NWRmYWVmNDc2MzgwMjkyN2E1M2ZhNjMxNWFmYzVhZGEzMmI1Yzc5N2M0YzhkYjkwNjZiZjQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=OxgBfyEqOlyNxgCmtdSf5nldg9e2vuDE3IAzSgixSN0YoMLijbUcDlqlrD0XBPWQnGEiqh1Na8JLPooELiCdDgFCPqDusrO7yUzd-E9mzmbczbPv02xzCpi364h1TqlJ8PFSKibEy9ogiOH1Q0hOOjn9gGVbBifAFnJQL-6m3fWkNObsTyku2Yp1xGw7YaoX8Mm4kfDNYQOfcHN2VnFpaPaaslxLpVAouBT7F95uqxN8RykyCuJEi4JPBK-nu8o1mBM1eMwRZ-zwiOKtkBz5nJVfC5RSPocqlCO%7ES38sDKMrV46Zj0dTjKwMV5Hhrnyz6NnlWPkwyGsHXi31tmAFgg__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-06-21 15:16:36--  https://cdn-lfs.huggingface.co/repos/e8/72/e872abef7b2278b5cf6a4f41d1455f5d309cdbd6310b2da0a6e9aecc840217e7/72926d774155dfaef4763802927a53fa6315afc5ada32b5c797c4c8db9066bf4?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27w2v_OA_CR_100d.bin.wv.vectors.npy%3B+filename%3D%22w2v_OA_CR_100d.bin.wv.vectors.npy%22%3B&Expires=1719242196&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTI0MjE5Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lOC83Mi9lODcyYWJlZjdiMjI3OGI1Y2Y2YTRmNDFkMTQ1NWY1ZDMwOWNkYmQ2MzEwYjJkYTBhNmU5YWVjYzg0MDIxN2U3LzcyOTI2ZDc3NDE1NWRmYWVmNDc2MzgwMjkyN2E1M2ZhNjMxNWFmYzVhZGEzMmI1Yzc5N2M0YzhkYjkwNjZiZjQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=OxgBfyEqOlyNxgCmtdSf5nldg9e2vuDE3IAzSgixSN0YoMLijbUcDlqlrD0XBPWQnGEiqh1Na8JLPooELiCdDgFCPqDusrO7yUzd-E9mzmbczbPv02xzCpi364h1TqlJ8PFSKibEy9ogiOH1Q0hOOjn9gGVbBifAFnJQL-6m3fWkNObsTyku2Yp1xGw7YaoX8Mm4kfDNYQOfcHN2VnFpaPaaslxLpVAouBT7F95uqxN8RykyCuJEi4JPBK-nu8o1mBM1eMwRZ-zwiOKtkBz5nJVfC5RSPocqlCO%7ES38sDKMrV46Zj0dTjKwMV5Hhrnyz6NnlWPkwyGsHXi31tmAFgg__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.159.227.123, 108.159.227.71, 108.159.227.86, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.159.227.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133344128 (127M) [binary/octet-stream]\n",
            "Saving to: ‘w2v_OA_CR_100d.bin.wv.vectors.npy’\n",
            "\n",
            "w2v_OA_CR_100d.bin. 100%[===================>] 127.17M   183MB/s    in 0.7s    \n",
            "\n",
            "2024-06-21 15:16:37 (183 MB/s) - ‘w2v_OA_CR_100d.bin.wv.vectors.npy’ saved [133344128/133344128]\n",
            "\n",
            "--2024-06-21 15:16:37--  https://huggingface.co/garyw/clinical-embeddings-100d-w2v-cr/resolve/main/w2v_OA_CR_100d.bin.trainables.syn1neg.npy\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.4, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/e8/72/e872abef7b2278b5cf6a4f41d1455f5d309cdbd6310b2da0a6e9aecc840217e7/db1819eafe7cc01a478aaf2fb7e3fc11bfeca24efafdff879a527e7f34e046e2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27w2v_OA_CR_100d.bin.trainables.syn1neg.npy%3B+filename%3D%22w2v_OA_CR_100d.bin.trainables.syn1neg.npy%22%3B&Expires=1719242197&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTI0MjE5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lOC83Mi9lODcyYWJlZjdiMjI3OGI1Y2Y2YTRmNDFkMTQ1NWY1ZDMwOWNkYmQ2MzEwYjJkYTBhNmU5YWVjYzg0MDIxN2U3L2RiMTgxOWVhZmU3Y2MwMWE0NzhhYWYyZmI3ZTNmYzExYmZlY2EyNGVmYWZkZmY4NzlhNTI3ZTdmMzRlMDQ2ZTI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=CiRRur8nmwyTiyr-mlDYFMPDcz911fqBAc8nB2t1YJwaGRye-ljfrhSgzR2fnDWqDWDLcYJddl2L3%7E5acFVbSwl-YA3ZDtjDkBRPBzdA610Z3WdUPfaIK%7Eoi7VHXTHAFyE9EGvGpwATajtbwYL4XSR3KXpBUHtmpk8-Uspa7jtVikNTjkdwAVpWiyx68u%7EqInpR1aTRWac-5nPUfqx%7EN8GV6DeP7hxHv4SacVzEmIzqYTXMlacczh5z-sya-l9ucFgpJ94Eip9SLLDBP1EBvm7yxzXdBCNKmzfzd6eX480uoSp8zPNXkkpf5X-sffDftkofiF-JUH22TwL3fVGrzdQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-06-21 15:16:37--  https://cdn-lfs.huggingface.co/repos/e8/72/e872abef7b2278b5cf6a4f41d1455f5d309cdbd6310b2da0a6e9aecc840217e7/db1819eafe7cc01a478aaf2fb7e3fc11bfeca24efafdff879a527e7f34e046e2?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27w2v_OA_CR_100d.bin.trainables.syn1neg.npy%3B+filename%3D%22w2v_OA_CR_100d.bin.trainables.syn1neg.npy%22%3B&Expires=1719242197&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTI0MjE5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lOC83Mi9lODcyYWJlZjdiMjI3OGI1Y2Y2YTRmNDFkMTQ1NWY1ZDMwOWNkYmQ2MzEwYjJkYTBhNmU5YWVjYzg0MDIxN2U3L2RiMTgxOWVhZmU3Y2MwMWE0NzhhYWYyZmI3ZTNmYzExYmZlY2EyNGVmYWZkZmY4NzlhNTI3ZTdmMzRlMDQ2ZTI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=CiRRur8nmwyTiyr-mlDYFMPDcz911fqBAc8nB2t1YJwaGRye-ljfrhSgzR2fnDWqDWDLcYJddl2L3%7E5acFVbSwl-YA3ZDtjDkBRPBzdA610Z3WdUPfaIK%7Eoi7VHXTHAFyE9EGvGpwATajtbwYL4XSR3KXpBUHtmpk8-Uspa7jtVikNTjkdwAVpWiyx68u%7EqInpR1aTRWac-5nPUfqx%7EN8GV6DeP7hxHv4SacVzEmIzqYTXMlacczh5z-sya-l9ucFgpJ94Eip9SLLDBP1EBvm7yxzXdBCNKmzfzd6eX480uoSp8zPNXkkpf5X-sffDftkofiF-JUH22TwL3fVGrzdQ__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.159.227.123, 108.159.227.71, 108.159.227.86, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.159.227.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133344128 (127M) [binary/octet-stream]\n",
            "Saving to: ‘w2v_OA_CR_100d.bin.trainables.syn1neg.npy’\n",
            "\n",
            "w2v_OA_CR_100d.bin. 100%[===================>] 127.17M   154MB/s    in 0.8s    \n",
            "\n",
            "2024-06-21 15:16:38 (154 MB/s) - ‘w2v_OA_CR_100d.bin.trainables.syn1neg.npy’ saved [133344128/133344128]\n",
            "\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.25.2)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.3 fastparquet-2024.5.0\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=d0293012c7fdbc03c9e51d4a9d0affa39ac4c31136d340a904ab0725c0210f5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/garyw/clinical-embeddings-100d-w2v-cr/resolve/main/w2v_OA_CR_100d.bin\n",
        "!wget https://huggingface.co/garyw/clinical-embeddings-100d-w2v-cr/resolve/main/w2v_OA_CR_100d.bin.wv.vectors.npy\n",
        "!wget https://huggingface.co/garyw/clinical-embeddings-100d-w2v-cr/resolve/main/w2v_OA_CR_100d.bin.trainables.syn1neg.npy\n",
        "!pip install fastparquet\n",
        "!pip install autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText, Word2Vec, KeyedVectors\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import nltk\n",
        "from torch.utils.data import Dataset,DataLoader, random_split\n",
        "import re\n",
        "from numpy import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re\n",
        "from autocorrect import Speller\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUJny_m5sDhW",
        "outputId": "1ce21033-bde0-497b-bca1-7abbdc4baf9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load('w2v_OA_CR_100d.bin')\n",
        "print(model.wv.get_vector('lymphangioleiomyomatosis'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfu7kv7UsEOk",
        "outputId": "1bcb4306-9ed1-46be-983e-89f49c723397"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.6044092   0.4017609  -0.717026   -0.2701869  -0.23817156 -0.34242344\n",
            " -0.15332928 -0.11580862 -0.36377856 -0.10749034  0.4498769   0.7072215\n",
            " -0.4689228  -0.48433578  1.050483    0.71655744 -0.6439546  -0.44996452\n",
            " -0.11657333  0.09194979  0.35634688  0.4884644   0.28647774 -0.496315\n",
            " -0.7018925  -0.25540805  0.14061369 -0.8933765  -0.52663106  0.40501425\n",
            "  0.17843099  0.21091795 -0.231396   -0.18487869  0.38206643  0.09275728\n",
            " -0.4573524   0.7668036   0.17861798  0.31376782 -0.49365893 -0.5377006\n",
            "  0.27592292 -0.04515044 -0.23638678 -0.5425362  -0.46474802  0.10646814\n",
            " -0.17016436 -0.07704978  0.17462458  0.27287003  0.5647319   0.1521702\n",
            "  0.1517999   0.2716373   0.21111147 -0.11035519  0.19445771  0.14426446\n",
            "  0.7005133  -0.71069545  0.01735174  0.30701727 -0.54055333 -0.0802884\n",
            " -0.1946127  -0.4616384  -0.4518422  -0.00218993 -0.3471012   0.60170263\n",
            " -0.47892392 -0.04716599  0.07105272  0.35743713 -0.4405513  -0.53299844\n",
            " -0.21108003  0.10141873  0.25599658 -0.22999842  0.21882392  0.50016177\n",
            " -0.234995    0.19636333 -0.29968616 -0.28172144  0.2259699  -0.16643997\n",
            "  0.53825945 -0.4934384  -0.0836745   0.00695672 -0.16958675 -0.17982216\n",
            " -0.23506676  0.22311303 -0.04329611  0.4834013 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_parquet('test-00000-of-00001-47685aa42db61e77.parquet', engine='fastparquet')\n",
        "train_data = pd.read_parquet('train-00000-of-00001-210cfe9263b99806.parquet', engine='fastparquet')\n",
        "valid_data = pd.read_parquet('valid-00000-of-00001-cc552de6d1a6fa4b.parquet', engine='fastparquet')\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cILS_EP_sIsi",
        "outputId": "67aa4a66-a6bf-4e4b-8712-0ffbb8a68d72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                                              query  \\\n",
              "0        MedNLI0  \\nTASK: Please classify the relationship betwe...   \n",
              "1        MedNLI1  \\nTASK: Please classify the relationship betwe...   \n",
              "2        MedNLI2  \\nTASK: Please classify the relationship betwe...   \n",
              "3        MedNLI3  \\nTASK: Please classify the relationship betwe...   \n",
              "4        MedNLI4  \\nTASK: Please classify the relationship betwe...   \n",
              "...          ...                                                ...   \n",
              "1417  MedNLI1417  \\nTASK: Please classify the relationship betwe...   \n",
              "1418  MedNLI1418  \\nTASK: Please classify the relationship betwe...   \n",
              "1419  MedNLI1419  \\nTASK: Please classify the relationship betwe...   \n",
              "1420  MedNLI1420  \\nTASK: Please classify the relationship betwe...   \n",
              "1421  MedNLI1421  \\nTASK: Please classify the relationship betwe...   \n",
              "\n",
              "             answer                               choices  gold  \n",
              "0        entailment  [entailment, contradiction, neutral]     0  \n",
              "1     contradiction  [entailment, contradiction, neutral]     1  \n",
              "2           neutral  [entailment, contradiction, neutral]     2  \n",
              "3        entailment  [entailment, contradiction, neutral]     0  \n",
              "4     contradiction  [entailment, contradiction, neutral]     1  \n",
              "...             ...                                   ...   ...  \n",
              "1417  contradiction  [entailment, contradiction, neutral]     1  \n",
              "1418        neutral  [entailment, contradiction, neutral]     2  \n",
              "1419     entailment  [entailment, contradiction, neutral]     0  \n",
              "1420  contradiction  [entailment, contradiction, neutral]     1  \n",
              "1421        neutral  [entailment, contradiction, neutral]     2  \n",
              "\n",
              "[1422 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bb3f591-e191-4c54-8f56-8c59d4e624b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>answer</th>\n",
              "      <th>choices</th>\n",
              "      <th>gold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MedNLI0</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MedNLI1</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MedNLI2</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MedNLI3</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MedNLI4</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>MedNLI1417</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>MedNLI1418</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>MedNLI1419</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>MedNLI1420</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1421</th>\n",
              "      <td>MedNLI1421</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1422 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bb3f591-e191-4c54-8f56-8c59d4e624b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bb3f591-e191-4c54-8f56-8c59d4e624b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bb3f591-e191-4c54-8f56-8c59d4e624b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-875d99c4-7187-4856-bdc1-62d17715784d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-875d99c4-7187-4856-bdc1-62d17715784d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-875d99c4-7187-4856-bdc1-62d17715784d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 1422,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1422,\n        \"samples\": [\n          \"MedNLI70\",\n          \"MedNLI1083\",\n          \"MedNLI613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1421,\n        \"samples\": [\n          \"\\nTASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label.\\n###\\nINPUT: [PRE] Liver failure- hx of encephalopathy, no bx seen in records DM type 2- non insulin dependent CHF Elevated PSA Pancreatitis Postive PPD Alcoholic cardiomyopathy [HYP]  The patient has multiple co-morbidities. \\nOUTPUT:\\n\",\n          \"\\nTASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label.\\n###\\nINPUT: [PRE] He was warmed, dried and stimulated. [HYP]  the patient was cooled\\nOUTPUT:\\n\",\n          \"\\nTASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label.\\n###\\nINPUT: [PRE] An emergent Hematology consultation was obtained. [HYP]  the patient has heparin induced thrombocytopenia\\nOUTPUT:\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"entailment\",\n          \"contradiction\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_pre_and_hyp(query):\n",
        "    start_pre = query.find(\"[PRE]\") + len(\"[PRE]\")\n",
        "    end_pre = query.find(\"[HYP]\")\n",
        "    start_hyp = query.find(\"[HYP]\") + len(\"[HYP]\")\n",
        "    end_hyp = query.find(\"OUTPUT:\")\n",
        "    premise = query[start_pre:end_pre].strip()\n",
        "    hypothesis = query[start_hyp:end_hyp].strip()\n",
        "    return premise,hypothesis"
      ],
      "metadata": {
        "id": "yAuRDuvgsVvy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectors_of_given_word(word):\n",
        "    try:\n",
        "       return model.wv.get_vector(word)\n",
        "    except:\n",
        "       #print(word)\n",
        "       return random.uniform(-1,1,size=(100,))\n",
        "       #return None"
      ],
      "metadata": {
        "id": "W2ONpORJsY3B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def found_vector(word):\n",
        "    try:\n",
        "       a = model.wv.get_vector(word)\n",
        "       return True\n",
        "    except:\n",
        "       return False"
      ],
      "metadata": {
        "id": "5s-PJiJgscJZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_a_number(number):\n",
        "    try:\n",
        "       a = float(number)\n",
        "       return True\n",
        "    except:\n",
        "       return False"
      ],
      "metadata": {
        "id": "dE1TOc25se8r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_by_pattern(word):\n",
        "    w = word\n",
        "    number_pattern = r'^[-+]?[0-9]*\\.?[0-9]+$'\n",
        "    yearold_pattern = r'^\\d+yearold$'\n",
        "    yo_pattern = r'^\\d+yo$'\n",
        "    hospital_pattern = r'^hospital\\d+$'\n",
        "    name_pattern = r'^name+\\d+$'\n",
        "    amount_pattern = r'\\d+.\\d+cc|\\d+.\\d+cm2$'\n",
        "    namepat_pattern = r'^namepattern\\d+$'\n",
        "    time_pattern = r'\\b(?:1[0-2]|0?[1-9])(?::[0-5][0-9])?(?:[ap]m)?\\b|\\d+:\\d'\n",
        "    stime_pattern = r'^\\d+s|\\d+h|\\d+hr$'\n",
        "    weight_pattern = r'\\b\\d+(?:\\.\\d+)?(?:kg|lb|mg|g)\\b'\n",
        "    if bool(re.match(number_pattern, word)):\n",
        "       w = 'number'\n",
        "    if bool(re.match(yearold_pattern, word)) or bool(re.match(yo_pattern, word)):\n",
        "       w = 'yearold'\n",
        "    if bool(re.match(hospital_pattern, word)):\n",
        "       w = 'hospital'\n",
        "    if bool(re.match(weight_pattern, word)):\n",
        "       w = 'weight'\n",
        "    if bool(re.match(amount_pattern, word)):\n",
        "       w = 'amount'\n",
        "    if bool(re.match(time_pattern, word)) or bool(re.match(stime_pattern, word)) or word == 'minuteslong':\n",
        "       w = 'time'\n",
        "    if bool(re.match(name_pattern, word)) or bool(re.match(namepat_pattern, word)) or word == 'lastname':\n",
        "       w = 'name'\n",
        "    if word == 'dangerousness':\n",
        "       w = 'dangerous'\n",
        "    if word == 'dr.':\n",
        "       w = 'doctor'\n",
        "    if word == '1st':\n",
        "       w = 'first'\n",
        "    return w"
      ],
      "metadata": {
        "id": "WEg8XHWUshvg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = r'^name+\\d+$'\n",
        "if bool(re.match(p, 'name3')):\n",
        "   print('is')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h876bXn1aS3P",
        "outputId": "93fdeed1-f2d1-4ef3-8cfd-3ea8d26aac72"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_spelling(word):\n",
        "    spell = Speller()\n",
        "    corrected_word = spell(word)\n",
        "    return corrected_word"
      ],
      "metadata": {
        "id": "YEmJ4FkCsjGI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_correct = \"hospitaal\"\n",
        "corrected_word = correct_spelling(word_to_correct)\n",
        "print(corrected_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gyn8qaysoIc",
        "outputId": "6a6f3f13-986a-4849-d653-d959efbd66f3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hospital\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_texts_tokens(texts_tokens):\n",
        "    newtexts_tokens = []\n",
        "    #i = 0\n",
        "    for tokens in texts_tokens:\n",
        "        newtokens = []\n",
        "        for word in tokens:\n",
        "            neword = clean_by_pattern(word)\n",
        "            #if not found_vector(neword):\n",
        "               #neword = correct_spelling(neword)\n",
        "               #if not found_vector(neword):\n",
        "                  #i = i + 1\n",
        "                  #if neword == 'osh':\n",
        "                      #print(tokens)\n",
        "                  #print(neword)\n",
        "            newtokens.append(neword)\n",
        "        newtexts_tokens.append(newtokens)\n",
        "    #print(i)\n",
        "    return newtexts_tokens"
      ],
      "metadata": {
        "id": "nAoYY5eTsrmC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_premise_and_hypothesis(premise,hypothesis):\n",
        "    premise = premise.replace('-','')\n",
        "    hypothesis = hypothesis.replace('-','')\n",
        "    premise = premise.replace('/','')\n",
        "    hypothesis = hypothesis.replace('/','')\n",
        "    premise = premise.replace('\\'','')\n",
        "    hypothesis = hypothesis.replace('\\'','')\n",
        "    premise = premise.replace('`','')\n",
        "    hypothesis = hypothesis.replace('`','')\n",
        "    premise = premise.replace('‰','')\n",
        "    hypothesis = hypothesis.replace('‰','')\n",
        "    premise = premise.replace('û','')\n",
        "    hypothesis = hypothesis.replace('û','')\n",
        "    premise = premise.replace('ª','')\n",
        "    hypothesis = hypothesis.replace('ª','')\n",
        "    #‰ûª\n",
        "    hypothesis = 'start ' + hypothesis\n",
        "    return premise,hypothesis"
      ],
      "metadata": {
        "id": "b7xJxUEQs6Yk"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_texts_tokens(data):\n",
        "    premise_texts_tokens = []\n",
        "    hypothesis_texts_tokens = []\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    for query,answer in zip(data['query'],data['answer']):\n",
        "        premise,hypothesis = find_pre_and_hyp(query)\n",
        "        premise,hypothesis = clean_premise_and_hypothesis(premise,hypothesis)\n",
        "        tokens_premise = nltk.word_tokenize(premise)\n",
        "        tokens_hypothesis = nltk.word_tokenize(hypothesis)\n",
        "        tokens_premise = [lemmatizer.lemmatize(token.lower()) for token in tokens_premise if token not in string.punctuation]\n",
        "        tokens_hypothesis = [lemmatizer.lemmatize(token.lower()) for token in tokens_hypothesis if token not in string.punctuation]\n",
        "        premise_texts_tokens.append(tokens_premise)\n",
        "        hypothesis_texts_tokens.append(tokens_hypothesis)\n",
        "    premise_texts_tokens = preprocess_texts_tokens(premise_texts_tokens)\n",
        "    hypothesis_texts_tokens = preprocess_texts_tokens(hypothesis_texts_tokens)\n",
        "    return premise_texts_tokens,hypothesis_texts_tokens"
      ],
      "metadata": {
        "id": "j6DWlSGVs9ms"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_premise_texts_tokens,train_hypothesis_texts_tokens = get_texts_tokens(train_data)\n",
        "test_premise_texts_tokens,test_hypothesis_texts_tokens = get_texts_tokens(test_data)"
      ],
      "metadata": {
        "id": "P03QILh1s-ue"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_premise_arr(premise_texts_tokens):\n",
        "    x_premise_arr = []\n",
        "    for text in premise_texts_tokens:\n",
        "        x = np.empty((0,100))\n",
        "        for word in text:\n",
        "            vectors = get_vectors_of_given_word(word)\n",
        "            vectors_np = np.array(vectors)\n",
        "            x = np.vstack([x, vectors_np])\n",
        "        x_premise_arr.append(x)\n",
        "    return x_premise_arr"
      ],
      "metadata": {
        "id": "MHx3VCGaf0dL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_premise_arr = get_x_premise_arr(train_premise_texts_tokens)\n",
        "test_x_premise_arr = get_x_premise_arr(test_premise_texts_tokens)"
      ],
      "metadata": {
        "id": "OJ7rLOl_f3oK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_hypothesis_arr(hypothesis_texts_tokens):\n",
        "    x_hypothesis_arr = []\n",
        "    for text in hypothesis_texts_tokens:\n",
        "        x = np.empty((0,100))\n",
        "        for word in text:\n",
        "            vectors = get_vectors_of_given_word(word)\n",
        "            vectors_np = np.array(vectors)\n",
        "            x = np.vstack([x, vectors_np])\n",
        "        x_hypothesis_arr.append(x)\n",
        "    return x_hypothesis_arr"
      ],
      "metadata": {
        "id": "6aZ3yBI0f5F3"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_hypothesis_arr = get_x_hypothesis_arr(train_hypothesis_texts_tokens)\n",
        "test_x_hypothesis_arr = get_x_hypothesis_arr(test_hypothesis_texts_tokens)"
      ],
      "metadata": {
        "id": "Qqk6pS0Yf-Lo"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_y_arr(data):\n",
        "    y_arr = []\n",
        "    for query,answer in zip(data['query'],data['answer']):\n",
        "        if answer == 'entailment':\n",
        "           y = [1,0,0]\n",
        "        elif answer == 'neutral':\n",
        "           y = [0,1,0]\n",
        "        elif answer == 'contradiction':\n",
        "           y = [0,0,1]\n",
        "        else:\n",
        "           print('should not get here')\n",
        "        y_arr.append(y)\n",
        "    return y_arr"
      ],
      "metadata": {
        "id": "S8B11CVrgCOv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_arr = get_y_arr(train_data)\n",
        "test_y_arr = get_y_arr(test_data)"
      ],
      "metadata": {
        "id": "9IlHIRz-gGXU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x_premise in train_x_premise_arr:\n",
        "    if x_premise.shape[0] == 0:\n",
        "       print(x_premise.shape)\n",
        "for x_premise in test_x_premise_arr:\n",
        "    if x_premise.shape[0] == 0:\n",
        "       print(x_premise.shape)\n",
        "\n",
        "for x_hypothesis in train_x_hypothesis_arr:\n",
        "    if x_hypothesis.shape[0] == 0:\n",
        "       print(x_hypothesis.shape)\n",
        "for x_hypothesis in test_x_hypothesis_arr:\n",
        "    if x_hypothesis.shape[0] == 0:\n",
        "       print(x_hypothesis.shape)"
      ],
      "metadata": {
        "id": "l8LBnPgqgJlA"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_x_hypothesis_arr))\n",
        "print(len(train_x_premise_arr))\n",
        "print(len(train_y_arr))\n",
        "print(len(test_x_hypothesis_arr))\n",
        "print(len(test_x_premise_arr))\n",
        "print(len(test_y_arr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHenNF_dgMgz",
        "outputId": "3fe1a0e8-1299-4ce7-d746-a0ac9d4d32e3"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11232\n",
            "11232\n",
            "11232\n",
            "1422\n",
            "1422\n",
            "1422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_hypothesis_arr , x_premise_arr, y_list):\n",
        "        self.samples = []\n",
        "        while x_premise_arr:\n",
        "            x_pre = x_premise_arr.pop()\n",
        "            x_hyp = x_hypothesis_arr.pop()\n",
        "            y = y_list.pop()\n",
        "            x_pre_tensor = torch.tensor(x_pre,dtype = torch.float32)#.cuda()\n",
        "            x_hyp_tensor = torch.tensor(x_hyp,dtype = torch.float32)#.cuda()\n",
        "            y_tensor = torch.tensor(y,dtype = torch.float32)#.cuda()\n",
        "            self.samples.append((x_pre_tensor,x_hyp_tensor,y_tensor))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]"
      ],
      "metadata": {
        "id": "IyB3aSY1gPX_"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_x_hypothesis_arr , train_x_premise_arr, train_y_arr)\n",
        "test_dataset = CustomDataset(test_x_hypothesis_arr , test_x_premise_arr, test_y_arr)"
      ],
      "metadata": {
        "id": "zxOM6AmEgSlw"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_maxlen(batch,i):\n",
        "    maxlen = 0\n",
        "    for tensr in batch:\n",
        "        if tensr[i].shape[0] > maxlen :\n",
        "           maxlen = tensr[i].shape[0]\n",
        "    return maxlen"
      ],
      "metadata": {
        "id": "mAUqHIUwgVGP"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    x_pres = []\n",
        "    x_hyps = []\n",
        "    ys = []\n",
        "    pre_max_len = get_maxlen(batch,0)\n",
        "    hyp_max_len = get_maxlen(batch,1)\n",
        "    for tensr in batch:\n",
        "        x_pre_tensor = tensr[0]\n",
        "        x_hyp_tensor = tensr[1]\n",
        "        y_tensor = tensr[2]\n",
        "        pre_pad_width = pre_max_len - x_pre_tensor.shape[0]\n",
        "        pre_leftpad_width = pre_pad_width // 2\n",
        "        pre_rightpad_width = pre_pad_width - pre_leftpad_width\n",
        "        pre_p1d = (0,0,pre_leftpad_width,pre_rightpad_width)\n",
        "        paded_x_pre_tensor = F.pad(x_pre_tensor,pre_p1d,\"constant\",0)\n",
        "        x_pres.append(paded_x_pre_tensor)\n",
        "        hyp_pad_width = hyp_max_len - x_hyp_tensor.shape[0]\n",
        "        hyp_leftpad_width = hyp_pad_width // 2\n",
        "        hyp_rightpad_width = hyp_pad_width - hyp_leftpad_width\n",
        "        hyp_p1d = (0,0,hyp_leftpad_width,hyp_rightpad_width)\n",
        "        paded_x_hyp_tensor = F.pad(x_hyp_tensor,hyp_p1d,\"constant\",0)\n",
        "        x_hyps.append(paded_x_hyp_tensor)\n",
        "        ys.append(y_tensor)\n",
        "    X_pre = torch.stack(x_pres,dim=0)\n",
        "    X_hyp = torch.stack(x_hyps,dim=0)\n",
        "    Y = torch.stack(ys,dim=0)\n",
        "    return [X_pre,X_hyp,Y]"
      ],
      "metadata": {
        "id": "fLgR4SIZgYCZ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_acc(model):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for x_pre, x_hyp, y in test_loader:\n",
        "        outputs = model(x_pre,x_hyp)\n",
        "        predicted_labels = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        predictions.extend(predicted_labels)\n",
        "        l1 = torch.argmax(y, dim=1).cpu().numpy()\n",
        "        true_labels.extend(l1)\n",
        "    model.train()\n",
        "    return accuracy_score(true_labels, predictions)"
      ],
      "metadata": {
        "id": "uR-rrsW9gZQn"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bsize = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=bsize,collate_fn=collate_fn, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=bsize,collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "qKi-n2KPghhp"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.lstm1 = nn.LSTM(100, 20, 1,batch_first = True)\n",
        "        self.lstm2 = nn.LSTM(100, 20, 1,batch_first = True)\n",
        "        self.attn = nn.Linear(40,1)\n",
        "        self.fc2 = nn.Linear(40, 20)\n",
        "        self.fc1 = nn.Linear(20, 3)\n",
        "\n",
        "    def forward(self,x_pre,x_hyp):\n",
        "        output_pre, (hn_pre, cn_pre) = self.lstm1(x_pre)\n",
        "        reshaped_output_pre = output_pre.reshape([output_pre.shape[1],output_pre.shape[0],output_pre.shape[2]])\n",
        "        output_pre_list = torch.chunk(reshaped_output_pre, reshaped_output_pre.size(0), dim=0)\n",
        "        output_pre_list = [tensor.squeeze(0) for tensor in output_pre_list]\n",
        "        xhyp_h0 = hn_pre\n",
        "        xhyp_c0 = cn_pre\n",
        "        output_hyp, (hn_hyp, cn_hyp) = self.lstm2(x_hyp, (xhyp_h0, xhyp_c0))\n",
        "        hn_hyp = hn_hyp.reshape([hn_hyp.shape[1],hn_hyp.shape[2]])\n",
        "\n",
        "        alpha_list = []\n",
        "        for h_pre in output_pre_list:\n",
        "            conc = torch.cat((h_pre,hn_hyp),dim=1)\n",
        "            alpha = torch.tanh(self.attn(conc))\n",
        "            alpha_list.append(alpha)\n",
        "        alphas = torch.stack(alpha_list)\n",
        "        alphas = nn.functional.softmax(alphas.reshape([alphas.shape[1],alphas.shape[0],1]))\n",
        "        context_vector = torch.sum((alphas * output_pre),dim=1)\n",
        "        cnc = torch.cat((context_vector,hn_hyp),dim=1)\n",
        "        x = torch.tanh(self.fc2(cnc))\n",
        "        x = self.fc1(x)\n",
        "        x = nn.functional.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HgSj5GyKrCrG"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN1, self).__init__()\n",
        "        self.lstm1 = nn.LSTM(100, 20, 1,batch_first = True)\n",
        "        self.lstm2 = nn.LSTM(100, 20, 1,batch_first = True)\n",
        "        self.attn = nn.Linear(40,1)\n",
        "        self.attn1 = nn.Linear(60,1)\n",
        "        self.fc2 = nn.Linear(40, 20)\n",
        "        self.fc1 = nn.Linear(20, 3)\n",
        "\n",
        "    def forward(self,x_pre,x_hyp):\n",
        "        output_pre, (hn_pre, cn_pre) = self.lstm1(x_pre)\n",
        "        reshaped_output_pre = output_pre.reshape([output_pre.shape[1],output_pre.shape[0],output_pre.shape[2]])\n",
        "        output_pre_list = torch.chunk(reshaped_output_pre, reshaped_output_pre.size(0), dim=0)\n",
        "        output_pre_list = [tensor.squeeze(0) for tensor in output_pre_list]\n",
        "        xhyp_h0 = hn_pre\n",
        "        xhyp_c0 = cn_pre\n",
        "        output_hyp, (hn_hyp, cn_hyp) = self.lstm2(x_hyp, (xhyp_h0, xhyp_c0))\n",
        "        hn_hyp = hn_hyp.reshape([hn_hyp.shape[1],hn_hyp.shape[2]])\n",
        "        output_hyp_list = torch.chunk(output_hyp, output_hyp.size(1), dim=1)\n",
        "        context_vector = self.get_last_context_vector(hn_hyp,output_pre_list,output_pre)\n",
        "        last_r = context_vector\n",
        "        for h_hyp in output_hyp_list:\n",
        "            h_hyp= h_hyp.reshape([h_hyp.shape[0],h_hyp.shape[2]])\n",
        "            n_r = self.get_context_vector(h_hyp,output_pre_list,last_r,output_pre)\n",
        "            last_r += n_r\n",
        "        context_vector = last_r\n",
        "        cnc = torch.cat((context_vector,hn_hyp),dim=1)\n",
        "        hstar = torch.tanh(self.fc2(cnc))\n",
        "        x = self.fc1(hstar)\n",
        "        x = nn.functional.softmax(x,dim=0)\n",
        "        return x\n",
        "\n",
        "    def get_last_context_vector(self,hn_hyp,output_pre_list,output_pre):\n",
        "        alpha_list = []\n",
        "        for h_pre in output_pre_list:\n",
        "            conc = torch.cat((h_pre,hn_hyp),dim=1)\n",
        "            alpha = torch.tanh(self.attn(conc))\n",
        "            alpha_list.append(alpha)\n",
        "        alphas = torch.stack(alpha_list)\n",
        "        alphas = nn.functional.softmax(alphas.reshape([alphas.shape[1],alphas.shape[0],1]),dim=0)\n",
        "        context_vector = torch.sum((alphas * output_pre),dim=1)\n",
        "        return context_vector\n",
        "\n",
        "    def get_context_vector(self,h_hyp,output_pre_list,last_R,output_pre):\n",
        "        alpha_list = []\n",
        "        for h_pre in output_pre_list:\n",
        "            conc = torch.cat((h_pre,h_hyp),dim=1)\n",
        "            conc = torch.cat((conc,last_R),dim=1)\n",
        "            alpha = torch.tanh(self.attn1(conc))\n",
        "            alpha_list.append(alpha)\n",
        "        alphas = torch.stack(alpha_list)\n",
        "        alphas = nn.functional.softmax(alphas.reshape([alphas.shape[1],alphas.shape[0],1]),dim=0)\n",
        "        context_vector = torch.sum((alphas * output_pre),dim=1)\n",
        "        return context_vector"
      ],
      "metadata": {
        "id": "OxUz-HfuglID"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = NN1()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "qpPNXO-5iQr9"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    for x_pre, x_hyp,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_pre,x_hyp)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_hyp,x_pre)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print(loss.item())\n",
        "\n",
        "    acc = get_model_acc(model)\n",
        "    print(acc)\n",
        "    if acc > 0.6976 :\n",
        "       torch.save(model,'model1.pth')\n",
        "    #print(loss.item())\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzp5L4mJiWEp",
        "outputId": "bc436412-3917-4228-decc-997a3fb5a289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5323488045007032\n",
            "0.5654008438818565\n",
            "0.5745428973277075\n",
            "0.5794655414908579\n",
            "0.5928270042194093\n",
            "0.5970464135021097\n",
            "0.60056258790436\n",
            "0.6125175808720112\n",
            "0.6139240506329114\n",
            "0.6132208157524613\n",
            "0.6139240506329114\n",
            "0.6167369901547117\n",
            "0.6068917018284107\n",
            "0.6068917018284107\n",
            "0.6167369901547117\n",
            "0.6195499296765119\n",
            "0.630801687763713\n",
            "0.6265822784810127\n",
            "0.6160337552742616\n",
            "0.6279887482419128\n",
            "0.6061884669479606\n",
            "0.6216596343178622\n",
            "0.6146272855133614\n",
            "0.6153305203938115\n",
            "0.6223628691983122\n",
            "0.630098452883263\n",
            "0.630098452883263\n",
            "0.6258790436005626\n",
            "0.6336146272855133\n",
            "0.6188466947960619\n",
            "0.6244725738396625\n",
            "0.6385372714486639\n",
            "0.630098452883263\n",
            "0.6223628691983122\n",
            "0.6230661040787623\n",
            "0.620253164556962\n",
            "0.629395218002813\n",
            "0.6378340365682138\n",
            "0.6420534458509142\n",
            "0.6286919831223629\n",
            "0.6258790436005626\n",
            "0.6258790436005626\n",
            "0.6195499296765119\n",
            "0.6371308016877637\n",
            "0.6378340365682138\n",
            "0.629395218002813\n",
            "0.6188466947960619\n",
            "0.6322081575246132\n",
            "0.6251758087201125\n",
            "0.6357243319268636\n",
            "0.630098452883263\n",
            "0.6322081575246132\n",
            "0.6385372714486639\n",
            "0.6371308016877637\n",
            "0.6329113924050633\n",
            "0.6265822784810127\n",
            "0.6265822784810127\n",
            "0.630801687763713\n",
            "0.629395218002813\n",
            "0.6322081575246132\n",
            "0.6322081575246132\n",
            "0.630098452883263\n",
            "0.6258790436005626\n",
            "0.630801687763713\n",
            "0.6350210970464135\n",
            "0.6462728551336147\n",
            "0.6265822784810127\n",
            "0.6364275668073136\n",
            "0.6322081575246132\n",
            "0.6279887482419128\n",
            "0.6329113924050633\n",
            "0.6343178621659634\n",
            "0.6322081575246132\n",
            "0.6286919831223629\n",
            "0.6329113924050633\n",
            "0.6364275668073136\n",
            "0.6237693389592124\n",
            "0.6350210970464135\n",
            "0.6371308016877637\n",
            "0.6322081575246132\n",
            "0.6378340365682138\n",
            "0.6364275668073136\n",
            "0.6378340365682138\n",
            "0.6364275668073136\n",
            "0.6336146272855133\n",
            "0.6364275668073136\n",
            "0.6216596343178622\n",
            "0.6329113924050633\n",
            "0.6258790436005626\n",
            "0.650492264416315\n",
            "0.6286919831223629\n"
          ]
        }
      ]
    }
  ]
}