{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjQJ4IxIVbSC",
        "outputId": "c9fb46d9-dd32-4fb4-bdf9-7bd8c035bb72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m888.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227138 sha256=795cc2b0b1b573c004ea820ca672cd226b97a5cb8a77fcb70057ef22521af2a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.12.0\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (1.25.2)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Installing collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.3 fastparquet-2024.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "!pip install fastparquet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import keyedvectors\n",
        "from scipy.spatial import distance\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset,DataLoader, random_split"
      ],
      "metadata": {
        "id": "ewoX7EtwVy0i"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"razent/SciFive-large-Pubmed_PMC-MedNLI\")\n",
        "SciFive_model = AutoModelForSeq2SeqLM.from_pretrained(\"razent/SciFive-large-Pubmed_PMC-MedNLI\")\n",
        "#model.cuda()\n",
        "\n",
        "sent_1 = \"the patient prescribed by antibiotic\"\n",
        "sent_2 = \"The patient has an infection\"\n",
        "text =  f\"mednli: sentence1: {sent_1} sentence2: {sent_2}\"\n",
        "\n",
        "encoding = tokenizer.encode_plus(text, padding='max_length', max_length=256, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "outputs = SciFive_model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=8,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "for output in outputs:\n",
        "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nZwmLmLWZGR",
        "outputId": "11eb5e7c-8990-4c36-a03f-358c4e68dfe9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entailment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_parquet('test-00000-of-00001-47685aa42db61e77.parquet', engine='fastparquet')\n",
        "train_data = pd.read_parquet('train-00000-of-00001-210cfe9263b99806.parquet', engine='fastparquet')\n",
        "valid_data = pd.read_parquet('valid-00000-of-00001-cc552de6d1a6fa4b.parquet', engine='fastparquet')\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2522
        },
        "id": "-imlKF7tWueQ",
        "outputId": "98ce27af-3e5f-486e-c9ec-773d4353ba27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id                                              query  \\\n",
              "0        MedNLI0  \\nTASK: Please classify the relationship betwe...   \n",
              "1        MedNLI1  \\nTASK: Please classify the relationship betwe...   \n",
              "2        MedNLI2  \\nTASK: Please classify the relationship betwe...   \n",
              "3        MedNLI3  \\nTASK: Please classify the relationship betwe...   \n",
              "4        MedNLI4  \\nTASK: Please classify the relationship betwe...   \n",
              "...          ...                                                ...   \n",
              "1417  MedNLI1417  \\nTASK: Please classify the relationship betwe...   \n",
              "1418  MedNLI1418  \\nTASK: Please classify the relationship betwe...   \n",
              "1419  MedNLI1419  \\nTASK: Please classify the relationship betwe...   \n",
              "1420  MedNLI1420  \\nTASK: Please classify the relationship betwe...   \n",
              "1421  MedNLI1421  \\nTASK: Please classify the relationship betwe...   \n",
              "\n",
              "             answer                               choices  gold  \n",
              "0        entailment  [entailment, contradiction, neutral]     0  \n",
              "1     contradiction  [entailment, contradiction, neutral]     1  \n",
              "2           neutral  [entailment, contradiction, neutral]     2  \n",
              "3        entailment  [entailment, contradiction, neutral]     0  \n",
              "4     contradiction  [entailment, contradiction, neutral]     1  \n",
              "...             ...                                   ...   ...  \n",
              "1417  contradiction  [entailment, contradiction, neutral]     1  \n",
              "1418        neutral  [entailment, contradiction, neutral]     2  \n",
              "1419     entailment  [entailment, contradiction, neutral]     0  \n",
              "1420  contradiction  [entailment, contradiction, neutral]     1  \n",
              "1421        neutral  [entailment, contradiction, neutral]     2  \n",
              "\n",
              "[1422 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-070bcbe9-cde0-4e1f-9dc3-a0fbf7506ac3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>answer</th>\n",
              "      <th>choices</th>\n",
              "      <th>gold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MedNLI0</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MedNLI1</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MedNLI2</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MedNLI3</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MedNLI4</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>MedNLI1417</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>MedNLI1418</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>MedNLI1419</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>MedNLI1420</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1421</th>\n",
              "      <td>MedNLI1421</td>\n",
              "      <td>\\nTASK: Please classify the relationship betwe...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[entailment, contradiction, neutral]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1422 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-070bcbe9-cde0-4e1f-9dc3-a0fbf7506ac3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-070bcbe9-cde0-4e1f-9dc3-a0fbf7506ac3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-070bcbe9-cde0-4e1f-9dc3-a0fbf7506ac3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a56a050-2f1f-4e0a-bf6a-f8837c1e770e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a56a050-2f1f-4e0a-bf6a-f8837c1e770e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a56a050-2f1f-4e0a-bf6a-f8837c1e770e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 1422,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1422,\n        \"samples\": [\n          \"MedNLI70\",\n          \"MedNLI1083\",\n          \"MedNLI613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1421,\n        \"samples\": [\n          \"\\nTASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label.\\n###\\nINPUT: [PRE] Liver failure- hx of encephalopathy, no bx seen in records DM type 2- non insulin dependent CHF Elevated PSA Pancreatitis Postive PPD Alcoholic cardiomyopathy [HYP]  The patient has multiple co-morbidities. \\nOUTPUT:\\n\",\n          \"\\nTASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label.\\n###\\nINPUT: [PRE] He was warmed, dried and stimulated. [HYP]  the patient was cooled\\nOUTPUT:\\n\",\n          \"\\nTASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label.\\n###\\nINPUT: [PRE] An emergent Hematology consultation was obtained. [HYP]  the patient has heparin induced thrombocytopenia\\nOUTPUT:\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"entailment\",\n          \"contradiction\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_pre_and_hyp(query):\n",
        "    start_pre = query.find(\"[PRE]\") + len(\"[PRE]\")\n",
        "    end_pre = query.find(\"[HYP]\")\n",
        "    start_hyp = query.find(\"[HYP]\") + len(\"[HYP]\")\n",
        "    end_hyp = query.find(\"OUTPUT:\")\n",
        "    premise = query[start_pre:end_pre].strip()\n",
        "    hypothesis = query[start_hyp:end_hyp].strip()\n",
        "\n",
        "    return premise,hypothesis"
      ],
      "metadata": {
        "id": "yqLOKmtxXdQt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(premise,hypothesis):\n",
        "    text =  f\"mednli: sentence1: {premise} sentence2: {hypothesis}\"\n",
        "    encoding = tokenizer.encode_plus(text, padding='max_length', max_length=256, return_tensors=\"pt\")\n",
        "    input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "    outputs = SciFive_model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=8,\n",
        "    early_stopping=True)\n",
        "    for output in outputs:\n",
        "        line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    return line"
      ],
      "metadata": {
        "id": "2uDbPyTtXnXT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "r = 0\n",
        "for query,answer in zip(test_data['query'],test_data['answer']):\n",
        "    count = count + 1\n",
        "    premise,hypothesis = find_pre_and_hyp(query)\n",
        "    an = get_answer(premise,hypothesis)\n",
        "    if an == answer:\n",
        "       r = r + 1\n",
        "print(r/count)"
      ],
      "metadata": {
        "id": "CrYdOsRJXqW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'TASK: Please classify the relationship between the given premise and hypothesis into one of the following labels: entailment, contradiction, or neutral. Return only the label. ### INPUT: [PRE] HISTORY: [**Known patient lastname **] is a 33-6/7 weeks male, twin #2, born at 0307 p.m. on [**2749-6-23**] via C-section for preeclampsia to a 34- year-old, G1, para 0, now 2, mother with an [**Name (NI) 2016**] of [**2749-8-5**]. [HYP] the patient is full term OUTPUT: '\n",
        "premise,hypothesis = find_pre_and_hyp(text)\n",
        "print(premise)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EViE-Y3VXstr",
        "outputId": "495b8657-7837-46b0-a573-7c5e690fb76f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HISTORY: [**Known patient lastname **] is a 33-6/7 weeks male, twin #2, born at 0307 p.m. on [**2749-6-23**] via C-section for preeclampsia to a 34- year-old, G1, para 0, now 2, mother with an [**Name (NI) 2016**] of [**2749-8-5**].\n",
            "the patient is full term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gsarti/biobert-nli\")\n",
        "sen2vec_model = AutoModel.from_pretrained(\"gsarti/biobert-nli\")\n",
        "#model.cuda()\n",
        "\n",
        "sent_1 = \"the patient hate antibiotic\"\n",
        "sent_2 = \"The patient has an infection\"\n",
        "text =  f\"mednli: sentence1: {sent_1} sentence2: {sent_2}\"\n",
        "\n",
        "s1 = tokenizer(premise,return_tensors=\"pt\")\n",
        "s2 = tokenizer(hypothesis,return_tensors=\"pt\")\n",
        "vec_1 = sen2vec_model(**s1)\n",
        "vec_2 = sen2vec_model(**s2)\n",
        "\n",
        "vecc_1 = vec_1[1][0].detach().numpy()\n",
        "vecc_2 = vec_2[1][0].detach().numpy()\n",
        "\n",
        "cnc_vec = np.concatenate((vecc_1, vecc_2))\n",
        "cosine_sim = 1 - distance.cosine(vecc_1, vecc_2)\n",
        "print('cosine similarity:', cosine_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeNOaZd-X6Zx",
        "outputId": "991d4a22-47ec-437b-f99a-f3fe486effe2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine similarity: 0.3269841969013214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cnc_vec))\n",
        "print(len(vecc_1))\n",
        "print(len(vecc_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3x_MsGnrq-E",
        "outputId": "9672e9b2-8d02-4128-ffd5-4963aca2df23"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536\n",
            "768\n",
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_list, y_list):\n",
        "        self.samples = []\n",
        "        for x,y in zip(x_list,y_list):\n",
        "            x_tensor = torch.tensor(x,dtype = torch.float32)\n",
        "            y_tensor = torch.tensor(y,dtype = torch.float32)\n",
        "            self.samples.append((x_tensor,y_tensor))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]"
      ],
      "metadata": {
        "id": "hI1Ih4gsmSdz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_list = []\n",
        "y_list = []\n",
        "for query,answer in zip(train_data['query'],train_data['answer']):\n",
        "    if answer == 'entailment':\n",
        "       y = [1,0,0]\n",
        "    elif answer == 'neutral':\n",
        "       y = [0,1,0]\n",
        "    elif answer == 'contradiction':\n",
        "       y = [0,0,1]\n",
        "    else:\n",
        "        print('should not get here')\n",
        "\n",
        "    premise,hypothesis = find_pre_and_hyp(query)\n",
        "    s1 = tokenizer(premise,return_tensors=\"pt\")\n",
        "    s2 = tokenizer(hypothesis,return_tensors=\"pt\")\n",
        "    vec_1 = sen2vec_model(**s1)\n",
        "    vec_2 = sen2vec_model(**s2)\n",
        "    vecc_1 = vec_1[1][0].detach().numpy()\n",
        "    vecc_2 = vec_2[1][0].detach().numpy()\n",
        "    x = np.concatenate((vecc_1, vecc_2))\n",
        "\n",
        "    x_list.append(x)\n",
        "    y_list.append(y)"
      ],
      "metadata": {
        "id": "p_uPnftojy9W"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIQdpd5cuPPa",
        "outputId": "447bd850-ac8e-4ca6-a10c-0db79662b11d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(x_list,y_list)"
      ],
      "metadata": {
        "id": "liSPv4JZ9VzM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.fc1 = nn.Linear(1536, 500)\n",
        "        self.bn1 = nn.BatchNorm1d(500)\n",
        "        self.fc2 = nn.Linear(500, 200)\n",
        "        self.bn2 = nn.BatchNorm1d(200)\n",
        "        self.fc3 = nn.Linear(200, 100)\n",
        "        self.bn3 = nn.BatchNorm1d(100)\n",
        "        self.fc4 = nn.Linear(100, 50)\n",
        "        self.bn4 = nn.BatchNorm1d(50)\n",
        "        self.fc5 = nn.Linear(50, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = nn.functional.softmax(self.fc5(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "tA_HiJk8BLbm"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "ivNVXezMan8q"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "-mBKC6VQBjvL"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "num_epochs = 2000\n",
        "for epoch in range(num_epochs):\n",
        "    for sente, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sente)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (i+1) % 100 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "    print(loss.item())\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pz3oqSaVBYqg",
        "outputId": "91fdeb86-c031-4ea7-8309-6f33c547cd40"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-166-5b445ac8e524>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(self.fc5(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9061316251754761\n",
            "0.8843598961830139\n",
            "0.8648734092712402\n",
            "0.845257580280304\n",
            "0.8790310025215149\n",
            "0.8454248905181885\n",
            "0.8176697492599487\n",
            "0.8359851837158203\n",
            "0.8081114888191223\n",
            "0.8076491355895996\n",
            "0.7798902988433838\n",
            "0.7592192888259888\n",
            "0.7473549842834473\n",
            "0.7384872436523438\n",
            "0.75857013463974\n",
            "0.7603501081466675\n",
            "0.7457093596458435\n",
            "0.725833535194397\n",
            "0.7227075695991516\n",
            "0.7245646119117737\n",
            "0.7009070515632629\n",
            "0.7169989943504333\n",
            "0.7060359716415405\n",
            "0.6996338367462158\n",
            "0.6852096915245056\n",
            "0.674544095993042\n",
            "0.690658688545227\n",
            "0.6870543360710144\n",
            "0.6808660626411438\n",
            "0.6826561093330383\n",
            "0.676261305809021\n",
            "0.67262864112854\n",
            "0.6796817779541016\n",
            "0.6699053049087524\n",
            "0.656233549118042\n",
            "0.6640235185623169\n",
            "0.6736311316490173\n",
            "0.6667000651359558\n",
            "0.6586175560951233\n",
            "0.6613309979438782\n",
            "0.6656649112701416\n",
            "0.6397616863250732\n",
            "0.66871178150177\n",
            "0.6641865372657776\n",
            "0.6527636647224426\n",
            "0.6538799405097961\n",
            "0.6677128672599792\n",
            "0.6742594838142395\n",
            "0.6517662405967712\n",
            "0.6605116724967957\n",
            "0.6619237661361694\n",
            "0.668663740158081\n",
            "0.6874857544898987\n",
            "0.6468190550804138\n",
            "0.6363878846168518\n",
            "0.6670117378234863\n",
            "0.6551726460456848\n",
            "0.6411997079849243\n",
            "0.6599034667015076\n",
            "0.6508239507675171\n",
            "0.6437666416168213\n",
            "0.6468735933303833\n",
            "0.6502906680107117\n",
            "0.6561076641082764\n",
            "0.6501996517181396\n",
            "0.6382691860198975\n",
            "0.6306880116462708\n",
            "0.6621553301811218\n",
            "0.6497639417648315\n",
            "0.634766161441803\n",
            "0.6412613391876221\n",
            "0.6399795413017273\n",
            "0.6295088529586792\n",
            "0.6329853534698486\n",
            "0.6295751333236694\n",
            "0.6302139759063721\n",
            "0.6369644999504089\n",
            "0.6410034894943237\n",
            "0.6566912531852722\n",
            "0.62562096118927\n",
            "0.6479249000549316\n",
            "0.6336182355880737\n",
            "0.6313631534576416\n",
            "0.6361986994743347\n",
            "0.6309075355529785\n",
            "0.6306184530258179\n",
            "0.6299800276756287\n",
            "0.6374194025993347\n",
            "0.6464182138442993\n",
            "0.6458367705345154\n",
            "0.6474039554595947\n",
            "0.6299190521240234\n",
            "0.6589149832725525\n",
            "0.6316925883293152\n",
            "0.641853928565979\n",
            "0.6430619359016418\n",
            "0.613665759563446\n",
            "0.6384918093681335\n",
            "0.6345345973968506\n",
            "0.6316816210746765\n",
            "0.643679141998291\n",
            "0.6220277547836304\n",
            "0.6256622672080994\n",
            "0.6297985315322876\n",
            "0.6479955315589905\n",
            "0.6278899908065796\n",
            "0.6334863305091858\n",
            "0.6256820559501648\n",
            "0.6368681192398071\n",
            "0.6332686543464661\n",
            "0.636947751045227\n",
            "0.6253657937049866\n",
            "0.63137286901474\n",
            "0.6437108516693115\n",
            "0.6337477564811707\n",
            "0.6523521542549133\n",
            "0.651824414730072\n",
            "0.6308881044387817\n",
            "0.648324191570282\n",
            "0.6423709392547607\n",
            "0.645065426826477\n",
            "0.6450831294059753\n",
            "0.6496482491493225\n",
            "0.6588090062141418\n",
            "0.6441853046417236\n",
            "0.6596053242683411\n",
            "0.6536176204681396\n",
            "0.638052761554718\n",
            "0.6396158933639526\n",
            "0.6361077427864075\n",
            "0.6369813680648804\n",
            "0.6288945078849792\n",
            "0.6318125128746033\n",
            "0.614602267742157\n",
            "0.6387495398521423\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-171-c9cd3e1042b9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msente\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "r = 0\n",
        "model.eval()\n",
        "for query,answer in zip(test_data['query'],test_data['answer']):\n",
        "    count = count + 1\n",
        "    premise,hypothesis = find_pre_and_hyp(query)\n",
        "\n",
        "    s1 = tokenizer(premise,return_tensors=\"pt\")\n",
        "    s2 = tokenizer(hypothesis,return_tensors=\"pt\")\n",
        "    #print(premise)\n",
        "    #print(hypothesis)\n",
        "    vec_1 = sen2vec_model(**s1)\n",
        "    vec_2 = sen2vec_model(**s2)\n",
        "    vecc_1 = vec_1[1][0].detach().numpy()\n",
        "    vecc_2 = vec_2[1][0].detach().numpy()\n",
        "    x = np.concatenate((vecc_1, vecc_2))\n",
        "    x_tensor = torch.tensor(x,dtype = torch.float32).unsqueeze(1).expand(-1,2)\n",
        "    x_tensor = torch.transpose(x_tensor,0,1)\n",
        "    #print(x_tensor)\n",
        "\n",
        "\n",
        "    a = np.argmax(model(x_tensor).detach().numpy()[0])\n",
        "    if a == 0:\n",
        "       #print('entailment')\n",
        "       an = 'entailment'\n",
        "    elif a == 1:\n",
        "       #print('neutral')\n",
        "       an = 'neutral'\n",
        "    elif a == 2:\n",
        "       #print('contradiction')\n",
        "       an = 'contradiction'\n",
        "    else:\n",
        "       print('should not get  here')\n",
        "\n",
        "    #print(answer)\n",
        "    #print('=====================================================================')\n",
        "    if an == answer:\n",
        "       r = r + 1\n",
        "    #print(r)\n",
        "    #print(count)\n",
        "print(r/count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrHgHlDdNtf1",
        "outputId": "44038fd1-5a8e-4f2e-bcef-08c4794a4895"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-166-5b445ac8e524>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(self.fc5(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6715893108298172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,'68.84accuracy.pth')"
      ],
      "metadata": {
        "id": "CHMZBvRQf5o3"
      },
      "execution_count": 162,
      "outputs": []
    }
  ]
}