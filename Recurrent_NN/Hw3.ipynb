{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E54DN9dcQ-Fa",
        "outputId": "28bf9b16-c91b-4c61-b8f8-75b213efdf22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GAsaI_2KFg9zkQqyTEkl5yl4wA7C39O7\n",
            "From (redirected): https://drive.google.com/uc?id=1GAsaI_2KFg9zkQqyTEkl5yl4wA7C39O7&confirm=t&uuid=71ff0f37-fdc7-4b7e-8e9a-af90d333f8d4\n",
            "To: /content/sentiment140.csv\n",
            "100% 203M/203M [00:02<00:00, 80.9MB/s]\n",
            "--2024-06-02 19:02:06--  https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.49, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/stanfordnlp/glove/6471382cdd837544bf3ac72497a38715e845897d265b2b424b4761832009c837?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27glove.6B.zip%3B+filename%3D%22glove.6B.zip%22%3B&response-content-type=application%2Fzip&Expires=1717614126&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzYxNDEyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9zdGFuZm9yZG5scC9nbG92ZS82NDcxMzgyY2RkODM3NTQ0YmYzYWM3MjQ5N2EzODcxNWU4NDU4OTdkMjY1YjJiNDI0YjQ3NjE4MzIwMDljODM3P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=tOGBn5Syxv%7ESa1TXlb9IOnq2pXJrfhhtdori-wU4Ex5GVYpemfgLlw4rq-Vc6-j30MfSm-hAX5ZvONiyitlKPwOE7QEMr6f6HNeZnljWo1snLxPxOsQlXFSYYQYUoSoHyAWZBNK7ERMzbExeM0IRNM3oBJa12V4pVQLCwsLmyxMHiDRl3UC5PqXGGgcFxE%7E6M08SyCSlWmvLhlSIUv6pQs%7EcZvnFxOybg0%7EFO8IAYwDxPfSLcGkNu%7EgsQIUeKHnCiel81idu-MRMP-CRunnopr-tpiWwUh1kvc-Cz6N1xIFCTqsJGbTSMuVctij3pANpHPFmvMotpFDR1xEmufc1cg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-06-02 19:02:06--  https://cdn-lfs.huggingface.co/stanfordnlp/glove/6471382cdd837544bf3ac72497a38715e845897d265b2b424b4761832009c837?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27glove.6B.zip%3B+filename%3D%22glove.6B.zip%22%3B&response-content-type=application%2Fzip&Expires=1717614126&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNzYxNDEyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9zdGFuZm9yZG5scC9nbG92ZS82NDcxMzgyY2RkODM3NTQ0YmYzYWM3MjQ5N2EzODcxNWU4NDU4OTdkMjY1YjJiNDI0YjQ3NjE4MzIwMDljODM3P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=tOGBn5Syxv%7ESa1TXlb9IOnq2pXJrfhhtdori-wU4Ex5GVYpemfgLlw4rq-Vc6-j30MfSm-hAX5ZvONiyitlKPwOE7QEMr6f6HNeZnljWo1snLxPxOsQlXFSYYQYUoSoHyAWZBNK7ERMzbExeM0IRNM3oBJa12V4pVQLCwsLmyxMHiDRl3UC5PqXGGgcFxE%7E6M08SyCSlWmvLhlSIUv6pQs%7EcZvnFxOybg0%7EFO8IAYwDxPfSLcGkNu%7EgsQIUeKHnCiel81idu-MRMP-CRunnopr-tpiWwUh1kvc-Cz6N1xIFCTqsJGbTSMuVctij3pANpHPFmvMotpFDR1xEmufc1cg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.94, 18.239.18.68, 18.239.18.29, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M   200MB/s    in 4.6s    \n",
            "\n",
            "2024-06-02 19:02:11 (179 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!gdown --id '1GAsaI_2KFg9zkQqyTEkl5yl4wA7C39O7'\n",
        "!wget https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\n",
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqsUsEKtuHz8",
        "outputId": "ccc71d65-1530-46ff-f670-fdf48cfb4ecf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sentiment140.csv') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    twits = []\n",
        "    y_arr = []\n",
        "    for row in reader:\n",
        "        text = row['text']\n",
        "        sentiment = int(row['sentiment'])\n",
        "        twits.append(text)\n",
        "        if sentiment == 0:\n",
        "           y_arr.append([0,1])\n",
        "        elif sentiment == 4:\n",
        "           y_arr.append([1,0])\n",
        "        else:\n",
        "           print('shouldnt get here')"
      ],
      "metadata": {
        "id": "XfIz9mzhuOhk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_pattern = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\"\n",
        "mention_pattern = r'@([A-Za-z0-9_]+)'\n",
        "hasgtag_pattern = r'#\\w+'\n",
        "cleaned_twits = []\n",
        "for text in twits:\n",
        "    cleaned_text = re.sub(url_pattern, \"<url>\", text)\n",
        "    cleaned_text = re.sub(mention_pattern, \"<mention>\", cleaned_text)\n",
        "    cleaned_text = re.sub(hasgtag_pattern, \"<hasgtag>\", cleaned_text)\n",
        "    cleaned_twits.append(cleaned_text)"
      ],
      "metadata": {
        "id": "v3B8_D_4VTAI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_tokens = []\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "for text in cleaned_twits:\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    filtered_tokens = [token for token in tokens if token not in string.punctuation]\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "    texts_tokens.append(filtered_tokens)"
      ],
      "metadata": {
        "id": "D39__lE5aO7P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(cleaned_twits[i])"
      ],
      "metadata": {
        "id": "SNsyuLZEf0FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3299b29-9152-40f9-a13b-438d5b097055"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<mention> <url> - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
            "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
            "<mention> I dived many times for the ball. Managed to save 50%  The rest go out of bounds\n",
            "my whole body feels itchy and like its on fire \n",
            "<mention> no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
            "<mention> not the whole crew \n",
            "Need a hug \n",
            "<mention> hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?\n",
            "<mention> nope they didn't have it \n",
            "<mention> que me muera ? \n",
            "spring break in plain city... it's snowing \n",
            "I just re-pierced my ears \n",
            "<mention> I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .\n",
            "<mention> It it counts, idk why I did either. you never talk to me anymore \n",
            "<mention> i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.\n",
            "<mention> I wish I got to watch it with you!! I miss you and <mention>  how was the premiere?!\n",
            "Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?\n",
            "about to file taxes \n",
            "<mention> ahh ive always wanted to see rent  love the soundtrack!!\n",
            "<mention> Oh dear. Were you drinking out of the forgotten table drinks? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_vectors(glove_file):\n",
        "    word_vectors = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.array(values[1:], dtype='float32')\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors"
      ],
      "metadata": {
        "id": "q3f1Cek8OSBT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file_path = './glove.6B.50d.txt'\n",
        "word_vectors = load_glove_vectors(glove_file_path)"
      ],
      "metadata": {
        "id": "AvMcf_N5AXWJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectors_of_given_word(word):\n",
        "    if word in word_vectors:\n",
        "       return word_vectors[word]\n",
        "    else:\n",
        "       return None"
      ],
      "metadata": {
        "id": "yVnEEr5AN88e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'feat'\n",
        "print(get_vectors_of_given_word(word))"
      ],
      "metadata": {
        "id": "Wli62L3YPcVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836e54d1-a869-41af-8311-7ee160f59bac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.4623     0.4685    -0.059266   0.31502   -0.20935    0.27924\n",
            " -0.02232    0.45211    0.41786    1.382      0.065629   0.0095435\n",
            " -1.1704    -0.26955    0.47909   -0.60971    1.1074     0.088239\n",
            " -0.73538   -0.10438   -0.68514    0.10573    0.26877   -0.99686\n",
            "  0.8547    -0.10986   -1.3006    -0.41911    0.45025   -0.29343\n",
            "  1.329      0.14538    0.028881  -0.10911    0.57076    0.19576\n",
            "  0.7261     0.8676    -0.88164   -0.65089   -0.61051   -0.78066\n",
            " -0.50536   -0.55755   -0.21071   -0.39848    0.22182   -0.1319\n",
            " -0.40512    0.17668  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectors_of_given_sentence(sentence):\n",
        "    vec = np.zeros(50)\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    ntokens = [token for token in tokens if token not in string.punctuation]\n",
        "    for t in ntokens:\n",
        "        arr = get_vectors_of_given_word(t)\n",
        "        arrlist = []\n",
        "        if not arr is None:\n",
        "           arrlist.append(arr)\n",
        "    for i in range(50):\n",
        "        count = 0\n",
        "        for arr in arrlist:\n",
        "            count += arr[i]\n",
        "        vec[i] = count/len(arrlist)\n",
        "\n",
        "    return vec"
      ],
      "metadata": {
        "id": "ED21XF4hYulc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I dont know what youre talking about'\n",
        "get_vectors_of_given_sentence(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdsmaXeTb5s4",
        "outputId": "6394c766-710d-4d63-ae6d-5d3ff930a0d2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.89466   ,  0.36603999,  0.37588   , -0.41817999,  0.58462   ,\n",
              "        0.18594   , -0.41907001, -0.46621001, -0.54903001,  0.02477   ,\n",
              "       -0.90815997, -0.48271   , -0.050742  , -0.74039   ,  1.43770003,\n",
              "       -0.01974   , -0.2384    ,  0.43154001, -0.66119999, -0.41275001,\n",
              "        0.25475001,  0.93497998,  0.81404001, -0.17296   ,  0.61295998,\n",
              "       -1.84749997, -0.27616   ,  0.27700999,  0.42346999, -0.11599   ,\n",
              "        3.6243    ,  0.12306   , -0.023526  , -0.24843   , -0.22375999,\n",
              "       -0.53941   , -0.62444001, -0.27711001,  0.49406001,  0.020234  ,\n",
              "       -0.23459999,  0.44512001,  0.53397   ,  0.66654003, -0.093662  ,\n",
              "       -0.035203  , -0.064194  ,  0.55997998, -0.66592997,  0.12177   ])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del twits\n",
        "del cleaned_twits\n",
        "del cleaned_text"
      ],
      "metadata": {
        "id": "VFdQkkqJzJGS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_arr = []\n",
        "max_len = 0\n",
        "for text in texts_tokens:\n",
        "    x = np.empty((0,50))\n",
        "    for word in text:\n",
        "        vectors = get_vectors_of_given_word(word)\n",
        "        if not vectors is None:\n",
        "            vectors_np = np.array(vectors)\n",
        "            x = np.vstack([x, vectors_np])\n",
        "    if max_len < x.shape[0]:\n",
        "         max_len = x.shape[0]\n",
        "    if x.shape[0] != 0:\n",
        "       x_arr.append(x)"
      ],
      "metadata": {
        "id": "vcQT20SL4V4Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del texts_tokens"
      ],
      "metadata": {
        "id": "iVr0ZT7AKIZh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_list, y_list):\n",
        "        self.samples = []\n",
        "        while x_list:\n",
        "            x = x_list.pop()\n",
        "            y = y_list.pop()\n",
        "            x_tensor = torch.tensor(x,dtype = torch.float32).cuda()\n",
        "            y_tensor = torch.tensor(y,dtype = torch.float32).cuda()\n",
        "            self.samples.append((x_tensor,y_tensor))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]"
      ],
      "metadata": {
        "id": "7TJfIsttWWFT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(x_arr,y_arr)"
      ],
      "metadata": {
        "id": "akSq0_49X7UV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del x_arr\n",
        "del y_arr"
      ],
      "metadata": {
        "id": "tOvGKh3uYllF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = random_split(dataset, [1270047, 317511])"
      ],
      "metadata": {
        "id": "mi_6SS4GaDvt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset"
      ],
      "metadata": {
        "id": "SP_PL9-EaqVS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_maxlen(batch):\n",
        "    maxlen = 0\n",
        "    for tensr in batch:\n",
        "        if tensr[0].shape[0] > maxlen :\n",
        "           maxlen = tensr[0].shape[0]\n",
        "    return maxlen"
      ],
      "metadata": {
        "id": "MpdIkUHJUvft"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    max_len = get_maxlen(batch)\n",
        "    for tensr in batch:\n",
        "        y_tensor = tensr[1]\n",
        "        x_tensor = tensr[0]\n",
        "        pad_width = max_len - x_tensor.shape[0]\n",
        "        leftpad_width = pad_width // 2\n",
        "        rightpad_width = pad_width - leftpad_width\n",
        "        p1d = (0,0,leftpad_width,rightpad_width)\n",
        "        paded_x_tensor = F.pad(tensr[0],p1d,\"constant\",0)\n",
        "        xs.append(paded_x_tensor)\n",
        "        ys.append(y_tensor)\n",
        "    X = torch.stack(xs,dim=0)\n",
        "    Y = torch.stack(ys,dim=0)\n",
        "    return [X,Y]"
      ],
      "metadata": {
        "id": "Fs5jvWT7KJr5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=512,collate_fn=collate_fn, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1,collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "Sm17blu7a4iY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN, self).__init__()\n",
        "        self.lstm = nn.LSTM(50, 20, 1,batch_first = True)\n",
        "        self.fc1 = nn.Linear(20, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, 32, 20)\n",
        "        c0 = torch.zeros(1, 32, 20)\n",
        "        output, _ = self.lstm(x)\n",
        "        x = output[:,-1,:]\n",
        "        x = nn.functional.softmax(self.fc1(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "ivb4S8p4TzKd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = NN()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6-xJd2_gGf-p"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for sente, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sente)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (i+1) % 100 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "    print(loss.item())\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyXB7KEzGkEQ",
        "outputId": "1c87adcd-caa3-47bb-9319-95c169dddbb4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-e13706f5eece>:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(self.fc1(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5498431921005249\n",
            "0.5524373054504395\n",
            "0.5554583668708801\n",
            "0.4906899034976959\n",
            "0.5367427468299866\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "true_labels = []\n",
        "i = 0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    outputs = model(inputs)\n",
        "    predicted_labels = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "    predictions.extend(predicted_labels)\n",
        "    l1 = torch.argmax(labels, dim=1).cpu().numpy()\n",
        "    true_labels.extend(l1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(true_labels, predictions, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(true_labels, predictions, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsGvpL_PQGyX",
        "outputId": "aeb30b25-6ebf-4bc3-c4d3-5ec0c15616ef"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-e13706f5eece>:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(self.fc1(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7255780114704687\n",
            "Precision: 0.7348572388589042\n",
            "Recall: 0.7255780114704687\n",
            "F1 Score: 0.7230525353891081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NN1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN1, self).__init__()\n",
        "        self.lstm = nn.GRU(50, 20, 1,batch_first = True)\n",
        "        self.fc1 = nn.Linear(20, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, 32, 20)\n",
        "        c0 = torch.zeros(1, 32, 20)\n",
        "        output, _ = self.lstm(x)\n",
        "        x = output[:,-1,:]\n",
        "        x = nn.functional.softmax(self.fc1(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "v0k50bH4buhJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model1 = NN1()\n",
        "model1.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WqnR3WHYcTBc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.train()\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for sente, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model1(sente)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (i+1) % 100 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "    print(loss.item())\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtxgqAyvckiM",
        "outputId": "70024f27-1506-4aaf-a45e-be07bfa9454a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-a3e62b2f3025>:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(self.fc1(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5815762281417847\n",
            "0.5288255214691162\n",
            "0.526593804359436\n",
            "0.5288028717041016\n",
            "0.5261754989624023\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "true_labels = []\n",
        "i = 0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    outputs = model1(inputs)\n",
        "    predicted_labels = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "    predictions.extend(predicted_labels)\n",
        "    l1 = torch.argmax(labels, dim=1).cpu().numpy()\n",
        "    true_labels.extend(l1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(true_labels, predictions, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(true_labels, predictions, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW8slfgkdZUR",
        "outputId": "90702e65-8c5c-4e44-f83e-44ea9d63a4de"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-a3e62b2f3025>:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = nn.functional.softmax(self.fc1(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7463772908655133\n",
            "Precision: 0.7481629196907097\n",
            "Recall: 0.7463772908655133\n",
            "F1 Score: 0.7459987769293417\n"
          ]
        }
      ]
    }
  ]
}